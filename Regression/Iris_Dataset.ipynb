{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conventional way to import pandas\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CSV file from the 'data' subdirectory using a relative path\n",
    "cols=['sepal length','sepal width','petal length','petal width','class']\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None,names=cols)\n",
    "# display the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding on Nominal Variable Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "one_hot_encoded=pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class_Iris-setosa</th>\n",
       "      <th>class_Iris-versicolor</th>\n",
       "      <th>class_Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal width  petal length  petal width  class_Iris-setosa  \\\n",
       "0          3.5           1.4          0.2                  1   \n",
       "1          3.0           1.4          0.2                  1   \n",
       "2          3.2           1.3          0.2                  1   \n",
       "3          3.1           1.5          0.2                  1   \n",
       "4          3.6           1.4          0.2                  1   \n",
       "\n",
       "   class_Iris-versicolor  class_Iris-virginica  \n",
       "0                      0                     0  \n",
       "1                      0                     0  \n",
       "2                      0                     0  \n",
       "3                      0                     0  \n",
       "4                      0                     0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a Python list of feature names\n",
    "feature_cols = ['sepal width','petal length','petal width','class_Iris-setosa', 'class_Iris-versicolor', 'class_Iris-virginica']\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "X = one_hot_encoded[feature_cols]\n",
    "\n",
    "# print the first 5 rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5.1\n",
       "1    4.9\n",
       "2    4.7\n",
       "3    4.6\n",
       "4    5.0\n",
       "Name: sepal length, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a Series from the DataFrame\n",
    "Y = one_hot_encoded['sepal length']\n",
    "\n",
    "# print the first 5 values\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting X and Y into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 6)\n",
      "(112,)\n",
      "(38, 6)\n",
      "(38,)\n"
     ]
    }
   ],
   "source": [
    "# default split is 75% for training and 25% for testing\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression in scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5209609366553503\n",
      "[ 0.44213063  0.91426633 -0.39683311  0.69485303 -0.12231585 -0.57253718]\n"
     ]
    }
   ],
   "source": [
    "# print the intercept and coefficients\n",
    "print(linreg.intercept_)\n",
    "print(linreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sepal width', 0.44213063296299643),\n",
       " ('petal length', 0.9142663349628987),\n",
       " ('petal width', -0.396833105514812),\n",
       " ('class_Iris-setosa', 0.6948530305858115),\n",
       " ('class_Iris-versicolor', -0.12231585120522798),\n",
       " ('class_Iris-virginica', -0.5725371793805825)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pair the feature names with the coefficients\n",
    "list(zip(feature_cols, linreg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38125987757901997\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out Regression on other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Sepal Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2765032068041506\n"
     ]
    }
   ],
   "source": [
    "# create a Python list of feature names\n",
    "feature_cols = ['sepal length','petal length','petal width','class_Iris-setosa', 'class_Iris-versicolor', 'class_Iris-virginica']\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "X = one_hot_encoded[feature_cols]\n",
    "\n",
    "# select a Series from the DataFrame\n",
    "y = one_hot_encoded['sepal width']\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "# compute the RMSE of our predictions\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict petal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32673903226161666\n"
     ]
    }
   ],
   "source": [
    "# create a Python list of feature names\n",
    "feature_cols = ['sepal length','sepal width','petal width','class_Iris-setosa', 'class_Iris-versicolor', 'class_Iris-virginica']\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "X = one_hot_encoded[feature_cols]\n",
    "\n",
    "# select a Series from the DataFrame\n",
    "y = one_hot_encoded['petal length']\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "# compute the RMSE of our predictions\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1701794851201285\n"
     ]
    }
   ],
   "source": [
    "# create a Python list of feature names\n",
    "feature_cols = ['sepal length','sepal width','petal length','class_Iris-setosa', 'class_Iris-versicolor', 'class_Iris-virginica']\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "X = one_hot_encoded[feature_cols]\n",
    "\n",
    "# select a Series from the DataFrame\n",
    "y = one_hot_encoded['petal width']\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "# compute the RMSE of our predictions\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor: Fit a new regression model to the training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=20, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=324)\n",
    "\n",
    "regressor = DecisionTreeRegressor(max_depth=20)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform prediction on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07211102550927963\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>sepal length</td>   <th>  R-squared:         </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>4.054e+31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Nov 2018</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:22:16</td>     <th>  Log-Likelihood:    </th>  <td>  5022.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   150</td>      <th>  AIC:               </th> <td>-1.003e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   144</td>      <th>  BIC:               </th> <td>-1.001e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sepal length</th>          <td>    1.0000</td> <td>  1.9e-16</td> <td> 5.26e+15</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sepal width</th>           <td> 5.551e-16</td> <td> 2.03e-16</td> <td>    2.732</td> <td> 0.007</td> <td> 1.53e-16</td> <td> 9.57e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>petal length</th>          <td> -1.11e-16</td> <td> 2.08e-16</td> <td>   -0.534</td> <td> 0.594</td> <td>-5.22e-16</td> <td>    3e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_Iris-setosa</th>     <td> -2.22e-15</td> <td>  7.5e-16</td> <td>   -2.961</td> <td> 0.004</td> <td> -3.7e-15</td> <td>-7.38e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_Iris-versicolor</th> <td>-1.443e-15</td> <td> 7.06e-16</td> <td>   -2.046</td> <td> 0.043</td> <td>-2.84e-15</td> <td>-4.86e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_Iris-virginica</th>  <td>-1.776e-15</td> <td> 8.23e-16</td> <td>   -2.160</td> <td> 0.032</td> <td> -3.4e-15</td> <td>-1.51e-16</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>143.654</td> <th>  Durbin-Watson:     </th> <td>   0.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  11.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.064</td>  <th>  Prob(JB):          </th> <td> 0.00341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.658</td>  <th>  Cond. No.          </th> <td>    163.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           sepal length   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 4.054e+31\n",
       "Date:                Thu, 22 Nov 2018   Prob (F-statistic):               0.00\n",
       "Time:                        19:22:16   Log-Likelihood:                 5022.4\n",
       "No. Observations:                 150   AIC:                        -1.003e+04\n",
       "Df Residuals:                     144   BIC:                        -1.001e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================\n",
       "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "sepal length              1.0000    1.9e-16   5.26e+15      0.000       1.000       1.000\n",
       "sepal width            5.551e-16   2.03e-16      2.732      0.007    1.53e-16    9.57e-16\n",
       "petal length           -1.11e-16   2.08e-16     -0.534      0.594   -5.22e-16       3e-16\n",
       "class_Iris-setosa      -2.22e-15    7.5e-16     -2.961      0.004    -3.7e-15   -7.38e-16\n",
       "class_Iris-versicolor -1.443e-15   7.06e-16     -2.046      0.043   -2.84e-15   -4.86e-17\n",
       "class_Iris-virginica  -1.776e-15   8.23e-16     -2.160      0.032    -3.4e-15   -1.51e-16\n",
       "==============================================================================\n",
       "Omnibus:                      143.654   Durbin-Watson:                   0.652\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               11.365\n",
       "Skew:                           0.064   Prob(JB):                      0.00341\n",
       "Kurtosis:                       1.658   Cond. No.                         163.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Note the difference in argument order\n",
    "model = sm.OLS(Y, X).fit()\n",
    "predictions = model.predict(X) # make the predictions by the model\n",
    "\n",
    "# Print out the statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model= 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X,Y)\n",
    "\n",
    "predictions = lm.predict(X)\n",
    "print('Accuracy of model=',lm.score(X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 train: 1.000, test : 1.000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## R2 score Evaluation\n",
    "y_train_pred=model.predict(X_train)\n",
    "y_test_pred=model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"r2 train: %.3f, test : %.3f\" %(r2_score(y_train,y_train_pred),r2_score(y_test,y_test_pred) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reference https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X.values, Y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Scores¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 0.0008 (0.0002)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet score: 0.0007 (0.0002)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Ridge score: 0.0173 (0.0031)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(KRR)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting score: 0.1893 (0.0619)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgboost score: 0.1763 (0.0174)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
