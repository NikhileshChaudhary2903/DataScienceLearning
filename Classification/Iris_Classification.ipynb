{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conventional way to import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read CSV file from the 'data' subdirectory using a relative path\n",
    "cols=['sepal length','sepal width','petal length','petal width','class']\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None,names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal length', 'sepal width', 'petal length', 'petal width', 'class'], dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "\n",
    "X=df[features]\n",
    "Y=df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting X and Y into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=1,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Scaling to train set and test set both Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std=sc.transform(X_train)\n",
    "X_test_std=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=0.1, fit_intercept=True,\n",
       "      max_iter=None, n_iter=40, n_jobs=1, penalty=None, random_state=0,\n",
       "      shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "ppn=Perceptron(n_iter=40,eta0=0.1,random_state=0)\n",
    "ppn.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Classification on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Samples: 2\n"
     ]
    }
   ],
   "source": [
    "y_pred=ppn.predict(X_test_std)\n",
    "print('Misclassified Samples: %d' % (y_test!=y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Perceptron Model: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of Perceptron Model: %.2f' % accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods=[]\n",
    "vals=[]\n",
    "mods.append('Perceptron Model')\n",
    "vals.append(accuracy_score(y_test,y_pred).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Samples: 2\n",
      "Accuracy of Logistic Regression Model: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr=LogisticRegression(C=1000.0,random_state=0)\n",
    "lr.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred=lr.predict(X_test_std)\n",
    "print('Misclassified Samples: %d' % (y_test!=y_pred).sum())\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of Logistic Regression Model: %.2f' % accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods.append('Logistic Regression Model')\n",
    "vals.append(accuracy_score(y_test,y_pred).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Samples: 1\n",
      "Accuracy of Support Vector Machine Model: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm=SVC(kernel='linear',random_state=0,C=1.0)\n",
    "svm.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred=svm.predict(X_test_std)\n",
    "print('Misclassified Samples: %d' % (y_test!=y_pred).sum())\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of Support Vector Machine Model: %.2f' % accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods.append('Support Vector Machine')\n",
    "vals.append(accuracy_score(y_test,y_pred).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Samples: 2\n",
      "Accuracy of Support Vector Machine Model with gamma: 0.96\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm=SVC(kernel='rbf',random_state=0,C=1.0,gamma=0.1)\n",
    "svm.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred=svm.predict(X_test_std)\n",
    "print('Misclassified Samples: %d' % (y_test!=y_pred).sum())\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of Support Vector Machine Model with gamma: %.2f' % accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Samples: 2\n",
      "Accuracy of Decision Tree Classifier with gamma: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree=DecisionTreeClassifier(criterion='entropy',max_depth=3,random_state=0)\n",
    "tree.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred=tree.predict(X_test_std)\n",
    "print('Misclassified Samples: %d' % (y_test!=y_pred).sum())\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of Decision Tree Classifier with gamma: %.2f' % accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods.append('Decision Tree Classifier')\n",
    "vals.append(accuracy_score(y_test,y_pred).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Samples: 2\n",
      "Accuracy of Random Forest Classifier with gamma: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest=RandomForestClassifier(criterion='entropy',n_estimators=10,random_state=1,n_jobs=2)\n",
    "forest.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred=forest.predict(X_test_std)\n",
    "print('Misclassified Samples: %d' % (y_test!=y_pred).sum())\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of Random Forest Classifier with gamma: %.2f' % accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods.append('Random Forest Classifier')\n",
    "vals.append(accuracy_score(y_test,y_pred).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. KNN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Samples: 2\n",
      "Accuracy of KNN Classifier with gamma: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=5,p=2,metric='minkowski')\n",
    "knn.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred=knn.predict(X_test_std)\n",
    "print('Misclassified Samples: %d' % (y_test!=y_pred).sum())\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of KNN Classifier with gamma: %.2f' % accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods.append('KNN Classifier')\n",
    "vals.append(accuracy_score(y_test,y_pred).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "from bokeh.palettes import Spectral6, brewer\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "ser_df=pd.DataFrame({'Model': mods, 'Accuracy_Value': vals})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ColumnDataSource(ser_df)\n",
    "\n",
    "p = figure(x_range=mods, plot_width=1000, plot_height=700)\n",
    "color_map = factor_cmap(field_name='Model', palette=Spectral6, factors=mods)\n",
    "p.vbar(x='Model', top='Accuracy_Value', source=source, width=0.70, color=color_map)\n",
    "\n",
    "p.title.text ='Comparison of Models'\n",
    "p.xaxis.axis_label = 'Model Types'\n",
    "p.yaxis.axis_label = \"Accuracy value of different models\"\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) petal width                    0.451645\n",
      " 2) petal length                   0.416091\n",
      " 3) sepal length                   0.102635\n",
      " 4) sepal width                    0.029628\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feat_labels = df.columns[:-1]\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=10000,\n",
    "                                random_state=1,n_jobs=-1)\n",
    "\n",
    "forest.fit(X_train_std, y_train)\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            feat_labels[indices[f]], \n",
    "                            importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ser_df=pd.DataFrame({'Features': feat_labels[indices].tolist(), 'Importance_Value': importances[indices].tolist()})\n",
    "\n",
    "source = ColumnDataSource(ser_df)\n",
    "\n",
    "p = figure(x_range=feat_labels[indices].tolist(), plot_width=800, plot_height=500)\n",
    "color_map = factor_cmap(field_name='Features', palette=Spectral6, factors=feat_labels[indices].tolist())\n",
    "p.vbar(x='Features', top='Importance_Value', source=source, width=0.70, color=color_map)\n",
    "\n",
    "p.title.text ='Feature Importance'\n",
    "p.xaxis.axis_label = 'Feature Name'\n",
    "p.yaxis.axis_label = \"Importance Score\"\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
