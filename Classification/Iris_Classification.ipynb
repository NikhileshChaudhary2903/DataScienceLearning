{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conventional way to import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read CSV file from the 'data' subdirectory using a relative path\n",
    "cols=['sepal length','sepal width','petal length','petal width','class']\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None,names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal length', 'sepal width', 'petal length', 'petal width', 'class'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "\n",
    "X=df[features]\n",
    "Y=df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting X and Y into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=1,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Scaling to train set and test set both Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std=sc.transform(X_train)\n",
    "X_test_std=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=0.1, fit_intercept=True,\n",
       "      max_iter=None, n_iter=40, n_jobs=1, penalty=None, random_state=0,\n",
       "      shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "ppn=Perceptron(n_iter=40,eta0=0.1,random_state=0)\n",
    "ppn.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Classification on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Samples: 2\n"
     ]
    }
   ],
   "source": [
    "y_pred=ppn.predict(X_test_std)\n",
    "print('Misclassified Samples: %d' % (y_test!=y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Perceptron Model: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of Perceptron Model: %.2f' % accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods=[]\n",
    "vals=[]\n",
    "mods.append('Perceptron Model')\n",
    "vals.append(accuracy_score(y_test,y_pred).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Samples: 2\n",
      "Accuracy of Logistic Regression Model: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr=LogisticRegression(C=1000.0,random_state=0)\n",
    "lr.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred=lr.predict(X_test_std)\n",
    "print('Misclassified Samples: %d' % (y_test!=y_pred).sum())\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of Logistic Regression Model: %.2f' % accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods.append('Logistic Regression Model')\n",
    "vals.append(accuracy_score(y_test,y_pred).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Samples: 1\n",
      "Accuracy of Support Vector Machine Model: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm=SVC(kernel='linear',random_state=0,C=1.0)\n",
    "svm.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred=svm.predict(X_test_std)\n",
    "print('Misclassified Samples: %d' % (y_test!=y_pred).sum())\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of Support Vector Machine Model: %.2f' % accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods.append('Support Vector Machine')\n",
    "vals.append(accuracy_score(y_test,y_pred).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "from bokeh.palettes import Spectral6, brewer\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "ser_df=pd.DataFrame({'Model': mods, 'Accuracy_Value': vals})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ColumnDataSource(ser_df)\n",
    "\n",
    "p = figure(x_range=mods, plot_width=700, plot_height=500)\n",
    "color_map = factor_cmap(field_name='Model', palette=Spectral6, factors=mods)\n",
    "p.vbar(x='Model', top='Accuracy_Value', source=source, width=0.70, color=color_map)\n",
    "\n",
    "p.title.text ='Comparison of Models'\n",
    "p.xaxis.axis_label = 'Model Types'\n",
    "p.yaxis.axis_label = \"Accuracy value of different models\"\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
